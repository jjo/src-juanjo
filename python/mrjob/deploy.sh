#!/bin/bash
set -u

load_vars() {
    echo "Loading vars from $(juju env)..."
eval $(juju status --format oneline | awk '/\<8020\>/{ print "hdfs_master=" $3 } /\<18080\>/{ print "spark=" $3 } /\<8088\>/ { print "yarn_master=" $3 }')
: ${hdfs_master?} ${spark?} ${yarn_master?}
}
do_deploy() {
    echo "# RUN:"
    echo juju-deployer -B -d -c juju-spark.yaml
}
do_showips() {
    load_vars
    (
    echo "http://${yarn_master}:8088/   yarn_master"
    echo "http://${hdfs_master}:50070/  hdfs_master"
    echo "http://${spark}:18080/        spark"
    )| column -t
}
do_novasec() {
: ${OS_USERNAME?} ${OS_PASSWORD?} ${OS_AUTH_URL?}
juju_env=$(juju env)
for net in 10.0.0.0/8 172.16.0.0/12 192.168.0.0/16 ;do
    (set -x; nova secgroup-add-rule juju-${juju_env} tcp 1 65535 $net)
done
}
do_confs() {
load_vars
cat > etc/core-site.xml <<EOF
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- autogenerated with $0 $* -->
<configuration>
<property>
    <name>fs.defaultFS</name>
    <value>hdfs://${hdfs_master}:8020</value>
</property>
<property>
    <name>dfs.namenode.http-address</name>
    <value>http://${hdfs_master}:50070</value>
</property>
</configuration>
EOF
cat > etc/yarn-site.xml <<EOF
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- autogenerated with $0 $* -->
<configuration>
    <property>
         <name>yarn.resourcemanager.hostname</name>
         <value>${yarn_master}</value>
    </property>
</configuration>
EOF
cat > etc/mapred-site.xml <<EOF
<?xml version="1.0" encoding="UTF-8"?>
<?xml-stylesheet type="text/xsl" href="configuration.xsl"?>
<!-- autogenerated with $0 $* -->
<configuration>
    <property>
         <name>mapreduce.framework.name</name>
         <value>yarn</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.address</name>
        <value>${yarn_master}:10020</value>
    </property>
    <property>
        <name>mapreduce.jobhistory.webapp.address</name>
        <value>${yarn_master}:19888</value>
    </property>
    <property>
        <name>mapreduce.jobtracker.staging.root.dir</name>
        <value>/user</value>
    </property>

</configuration>
EOF
more etc/*-site.xml | cat
}
do_dfshome() {
    : ${JAVA_HOME?} ${HADOOP_HOME?}
    (set -x
    hdfs dfs -mkdir /user/${USER?}
    hdfs dfs -chown $USER /user/$USER
    )
}
do_hosts() {
    juju ssh yarn-master/0 egrep JUJU /etc/hosts > etc/hosts
    echo "# RUN:"
    echo "egrep -q JUJU /etc/hosts || (set -x; cat $PWD/etc/hosts | sudo tee -a /etc/hosts)"
}
do_data() {
    f=star_wars_kid.log
    juju ssh --pty=false yarn-master/0 <<EOF
set -x
test -s $f|| { wget -q -O $f.xz.tmp https://swift.canonistack.canonical.com/v1/AUTH_5560a64dbc8043b48619ade81f068c71/ubuconla/$f.xz && mv -f $f.xz.tmp $f.xz && unxz -v $f.xz ;}
hdfs dfs -mkdir -p /user/ubuntu/ubuconla
hdfs dfs -put $f /user/ubuntu/ubuconla/$f
EOF
    #hdfs dfs -mkdir -p hdfs:///user/jjo/ubuconla/mrjob-output
    hdfs dfs -ls -d hdfs:///user/ubuntu/ubuconla/star_wars_kid.log

}
do_show_data_s3() {
    # http://aws.amazon.com/datasets/8172056142375670
    ngram=eng-us-all/1gram/data
    echo "# RUN:"
    echo "hdfs dfs -mkdir -p $(dirname /ngrams/${ngram})"
    echo 'hadoop distcp  -D fs.s3n.awsAccessKeyId="${AWS_ACCESS_KEY_ID?}" -D fs.s3n.awsSecretAccessKey="${AWS_SECRET_ACCESS_KEY?}" ' \
         "s3n://datasets.elasticmapreduce/ngrams/books/20090715/${ngram} hdfs:///ngrams/${ngram}"
}
do_show_run() {
    echo hdfs dfs -rm -r /user/jjo/ubuconla/mrjob-output
    echo ./j04-entropy.py -r hadoop  hdfs:///user/ubuntu/ubuconla/star_wars_kid.log  -o hdfs:///user/jjo/ubuconla/mrjob-output
    echo hdfs dfs -get hdfs:///user/jjo/ubuconla/mrjob-output/part-00000 /tmp
}
# e.g.: hadoop_daemon_ctl compute-slave/0 hdfs datanode start
#     /usr/local/hadoop/data/cache/hadoop/dfs/name/current/
hadoop_daemon_ctl() {
    local unit=$1 user=$2 daemon=$3 action=$4 type
    case "$user" in yarn) type=yarn;; *) type=hadoop;; esac
    set -x
    juju ssh --pty=false $unit "sudo su - $user" <<EOF
bash -c 'set -a;. /etc/environment;set -x;/usr/lib/hadoop/sbin/${type}-daemon.sh --config /etc/hadoop/conf $action $daemon'
EOF
}
do_datanode_optimize() {
    #compute_slaves=$(juju status compute-slave |egrep -o '\S+/[0-9]+')
    juju run --service=compute-slave "
test -d /mnt/dfs/name && exit 0
ls -al /usr/local/hadoop/data/cache/hadoop/dfs/name
set -a;. /etc/environment
set -x
sudo -u hdfs /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf stop  datanode
mkdir -p /mnt/dfs
mv /usr/local/hadoop/data/cache/hadoop/dfs/name /mnt/dfs/
ln -s /mnt/dfs/name /usr/local/hadoop/data/cache/hadoop/dfs/name
sudo -u hdfs /usr/lib/hadoop/sbin/hadoop-daemon.sh --config /etc/hadoop/conf start  datanode
ls -al /usr/local/hadoop/data/cache/hadoop/dfs/name
"
}
do_build_lzo() {
    unit=spark/0
    if [ -s lib/hadoop-lzo.tar.gz ] ;then
        also_to=spark/0
    else
        also_to=
        juju ssh --pty=false $unit << EOF
sudo apt-get install -qy git ant liblzo2-dev
git clone git://github.com/cloudera/hadoop-lzo
cd hadoop-lzo
curl https://gist.githubusercontent.com/jjo/41e5d95d8a33fd3f5e01/raw/df04db42e2a39a4a7af889505541a849108fd354/cloudera-hadoop-lzo-fix_build_xml.diff |patch -p1 -N
CLASSPATH=$(ls $HADOOP_HOME/share/hadoop/common/hadoop-common-?.?.?.jar) CFLAGS=-m64 CXXFLAGS=-m64 ant compile-native tar
sudo cp -p build/native/Linux-amd64-64/lib/*  /usr/lib/hadoop/lib/native/
sudo cp -p build/hadoop-lzo-0.4.15.jar /usr/lib/hadoop/lib/
sudo tar zcvf /tmp/hadoop-lzo.tar.gz /usr/lib/hadoop/lib/hadoop-lzo* /usr/lib/hadoop/lib/native/libgpl*
EOF
        juju scp spark/0:/tmp/hadoop-lzo.tar.gz ./lib
    fi
    ls -l lib/hadoop-lzo.tar.gz
}
do_dist_lzo() {
    compute_slaves=$(juju status compute-slave |egrep -o '\S+/[0-9]+')
    for i in spark/0 ${compute_slaves};do
        (set -x;juju scp ./lib/hadoop-lzo.tar.gz $i:)
    done
    juju run --service=compute-slave,spark "
sudo tar -C / -zxvf ~ubuntu/hadoop-lzo.tar.gz
set -a;. /etc/environment
set -x
sudo -u yarn /usr/lib/hadoop/sbin/yarn-daemon.sh --config /etc/hadoop/conf stop  nodemanager
sudo -u yarn /usr/lib/hadoop/sbin/yarn-daemon.sh --config /etc/hadoop/conf start nodemanager
"
    (set -x
    juju ssh --pty=false spark/0 'sudo su - ' << EOF
sed -i 's|^</configuration>|<property><name>io.compression.codecs</name><value>org.apache.hadoop.io.compress.GzipCodec,org.apache.hadoop.io.compress.DefaultCodec,org.apache.hadoop.io.compress.BZip2Codec,com.hadoop.compression.lzo.LzoCodec,com.hadoop.compression.lzo.LzopCodec</value></property><property><name>io.compression.codec.lzo.class</name><value>com.hadoop.compression.lzo.LzoCodec</value></property></configuration>|' /etc/hadoop/conf/core-site.xml
EOF
    )
}
do_hint_spark() {
    echo "juju ssh spark/0 'pyspark --jars /usr/lib/hadoop/lib/hadoop-lzo-0.4.15.jar'"
}

case ${1:-} in
    deploy)  do_deploy;;
    showips) do_showips;;
    novasec) do_novasec;;
    hosts) do_hosts;;
    confs) do_confs;;
    datanode-opt) do_datanode_optimize;;
    dfshome) do_dfshome;;
    data) do_data;;
    show-run) do_show_run;;
    show-data-s3) do_show_data_s3;;
    build-lzo) do_build_lzo;;
    dist-lzo) do_dist_lzo;;
    hint-spark) do_hint_spark;;
    hadoop-daemon-ctl) shift;hadoop_daemon_ctl $*;;
    *)
        args="$(egrep -o '^\s+\S{2,}\)' $0|sed 's/)/ /'|xargs|sed 's/ /|/g')"
        echo "usage: $0 {$args}";;
esac

# vim: et si sw=4 ts=4
